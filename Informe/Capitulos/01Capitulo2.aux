\relax 
\providecommand\hyper@newdestlabel[2]{}
\citation{bengio2009learning}
\citation{bishop2006pattern}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Fundamentos te\'oricos}{7}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Aprendizaje supervisado}{8}{section.2.1}}
\newlabel{cap2:sec:supervisado}{{2.1}{8}{Aprendizaje supervisado}{section.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Sistemas de regresi\'on y clasificaci\'on}{8}{subsection.2.1.1}}
\newlabel{cap2:subsec:reg-clasif}{{2.1.1}{8}{Sistemas de regresión y clasificación}{subsection.2.1.1}{}}
\newlabel{eq:mse}{{2.1}{8}{Sistemas de regresión y clasificación}{equation.2.1.1}{}}
\newlabel{eq:d_mse}{{2.2}{8}{Sistemas de regresión y clasificación}{equation.2.1.2}{}}
\citation{van2014analysis}
\citation{bishop2006pattern}
\citation{cotter2011better}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Optimizaci\'on}{10}{subsection.2.1.2}}
\newlabel{cap2:subsec:optimizacion}{{2.1.2}{10}{Optimización}{subsection.2.1.2}{}}
\GLX@entry{GD}{n}{acr}{a}{10}
\newlabel{eq:gd}{{2.6}{10}{Optimización}{equation.2.1.6}{}}
\citation{ds2016deepdive}
\citation{nesterov1983method}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Influencia del \textit  {momentum} en la optimizaci\'on por gradiente descendiente (GD). Izquierda, GD sin \textit  {momentum}. Derecha, GD con \textit  {momentum}.\relax }}{11}{figure.caption.6}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:momentum}{{2.1}{11}{Influencia del \textit {momentum} en la optimización por gradiente descendiente (GD). Izquierda, GD sin \textit {momentum}. Derecha, GD con \textit {momentum}.\relax }{figure.caption.6}{}}
\GLX@entry{SGD}{n}{acr}{a}{11}
\GLX@entry{NAG}{n}{acr}{a}{11}
\citation{dean2012large}
\citation{zeiler2012adadelta}
\citation{li2015cs231n}
\citation{ds2016deepdive}
\citation{ruder2016optimization}
\citation{bayer2016climin}
\newlabel{eq:adagrad}{{2.11}{12}{Optimización}{equation.2.1.11}{}}
\citation{powers2011evaluation}
\citation{yang1999re}
\citation{sokolova2009systematic}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}M\'etricas de evaluaci\'on}{13}{subsection.2.1.3}}
\newlabel{cap2:subsec:metricas}{{2.1.3}{13}{Métricas de evaluación}{subsection.2.1.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.3.1}Clasificaci\'on}{13}{subsubsection.2.1.3.1}}
\GLX@entry{ACC}{n}{acr}{a}{13}
\citation{lehmann2006theory}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces Medidas de evaluaci\'on en problemas de clasificaci\'on multi-clases.\relax }}{15}{table.caption.7}}
\newlabel{tab:metricas-multiclase}{{2.1}{15}{Medidas de evaluación en problemas de clasificación multi-clases.\relax }{table.caption.7}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2.2}{\ignorespaces Esquema de matriz de confusi\'on para evaluar predicciones sobre 3 clases.\relax }}{15}{table.2.2}}
\newlabel{tab:confusion-matrix}{{2.2}{15}{Esquema de matriz de confusión para evaluar predicciones sobre 3 clases.\relax }{table.2.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.3.2}Regresi\'on}{15}{subsubsection.2.1.3.2}}
\GLX@entry{MSE}{n}{acr}{a}{15}
\GLX@entry{MAE}{n}{acr}{a}{15}
\citation{kohavi1995study}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.4}Ajuste de hiperpar\'ametros}{16}{subsection.2.1.4}}
\newlabel{cap2:subsec:ajuste-parametros}{{2.1.4}{16}{Ajuste de hiperparámetros}{subsection.2.1.4}{}}
\citation{donoho2000high}
\citation{bergstra2012random}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Tipos de ajuste que puede lograr un modelo sobre los datos que utiliza para su entrenamiento.\relax }}{17}{figure.caption.8}}
\newlabel{fig:overfitting}{{2.2}{17}{Tipos de ajuste que puede lograr un modelo sobre los datos que utiliza para su entrenamiento.\relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.5}Control de la optimizaci\'on}{17}{subsection.2.1.5}}
\newlabel{cap2:subsec:control-optimiz}{{2.1.5}{17}{Control de la optimización}{subsection.2.1.5}{}}
\citation{gonzalez1995redes}
\citation{haykin2004comprehensive}
\citation{lopez2008redes}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Redes Neuronales Artificiales}{18}{section.2.2}}
\newlabel{cap2:sec:redesneuronales}{{2.2}{18}{Redes Neuronales Artificiales}{section.2.2}{}}
\GLX@entry{RNA}{n}{acr}{a}{18}
\GLX@entry{RNA}{n}{acr}{a}{18}
\GLX@entry{RNA}{n}{acr}{a}{18}
\citation{haykin2004comprehensive}
\@writefile{lot}{\contentsline {table}{\numberline {2.3}{\ignorespaces Diferencias entre cerebro humano y computadora convencional\relax }}{19}{table.caption.9}}
\newlabel{tab:table1}{{2.3}{19}{Diferencias entre cerebro humano y computadora convencional\relax }{table.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Modelo matem\'atico de una neurona.\relax }}{19}{figure.caption.10}}
\newlabel{fig:neurona_modelo}{{2.3}{19}{Modelo matemático de una neurona.\relax }{figure.caption.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Arquitectura}{19}{subsection.2.2.1}}
\newlabel{cap2:subsec:arquitectura}{{2.2.1}{19}{Arquitectura}{subsection.2.2.1}{}}
\citation{haykin2004comprehensive}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Arquitectura b\'asica de un MLP con 4 capas.\relax }}{20}{figure.caption.11}}
\newlabel{fig:mlp}{{2.4}{20}{Arquitectura básica de un MLP con 4 capas.\relax }{figure.caption.11}{}}
\GLX@entry{MLP}{n}{acr}{a}{20}
\citation{van2014analysis}
\citation{dettmers2015deep}
\citation{van2014analysis}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Funciones de activaci\'on}{21}{subsection.2.2.2}}
\newlabel{cap2:subsec:funactiv}{{2.2.2}{21}{Funciones de activación}{subsection.2.2.2}{}}
\newlabel{eq:activ}{{2.22}{21}{Funciones de activación}{equation.2.2.22}{}}
\newlabel{eq:sigmoideas}{{2.23}{21}{Funciones de activación}{equation.2.2.23}{}}
\GLX@entry{ReLU}{n}{acr}{a}{21}
\GLX@entry{ReLU}{n}{acr}{a}{21}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Visualizaci\'on de las funciones de activaci\'on para $-3 \leq z \leq 3$.\relax }}{22}{figure.caption.12}}
\newlabel{fig:activaciones}{{2.5}{22}{Visualización de las funciones de activación para $-3 \leq z \leq 3$.\relax }{figure.caption.12}{}}
\GLX@entry{ReLU}{n}{acr}{a}{22}
\GLX@entry{ReLU}{n}{acr}{a}{22}
\@writefile{lot}{\contentsline {table}{\numberline {2.4}{\ignorespaces Funciones de activaci\'on desarrolladas, detallando para cada una tanto su expresi\'on la de su respectiva derivada anal\IeC {\'\i }tica.\relax }}{22}{table.caption.13}}
\newlabel{tab:activaciones}{{2.4}{22}{Funciones de activación desarrolladas, detallando para cada una tanto su expresión la de su respectiva derivada analítica.\relax }{table.caption.13}{}}
\citation{williams1986learning}
\citation{nielsen2015neural}
\citation{ng2012ufldl}
\citation{ng2012ufldl}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Retropropagaci\'on}{23}{subsection.2.2.3}}
\newlabel{cap2:subsubsec:backprop}{{2.2.3}{23}{Retropropagación}{subsection.2.2.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Aprendizaje profundo}{23}{section.2.3}}
\newlabel{cap2:sec:deeplearning}{{2.3}{23}{Aprendizaje profundo}{section.2.3}{}}
\citation{hochreiter2001gradient}
\citation{nielsen2015neural}
\citation{bengio2009learning}
\citation{erhan2010does}
\citation{hochreiter1997long}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Redes Neuronales Profundas}{24}{subsection.2.3.1}}
\newlabel{cap2:subsec:redes-profundas}{{2.3.1}{24}{Redes Neuronales Profundas}{subsection.2.3.1}{}}
\citation{li2015cs231n}
\citation{he2015delving}
\citation{glorot2010understanding}
\citation{li2015cs231n}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Tratamiento sobre los pesos sin\'apticos}{25}{subsection.2.3.2}}
\newlabel{cap2:subsec:pesos-sinapticos}{{2.3.2}{25}{Tratamiento sobre los pesos sinápticos}{subsection.2.3.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.2.1}Inicializaci\'on}{25}{subsubsection.2.3.2.1}}
\newlabel{cap2:subsubsec:init-pesos}{{2.3.2.1}{25}{Inicialización}{subsubsection.2.3.2.1}{}}
\GLX@entry{ReLU}{n}{acr}{a}{25}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.2.2}Regularizaci\'on}{25}{subsubsection.2.3.2.2}}
\newlabel{cap2:subsubsec:reg-pesos}{{2.3.2.2}{25}{Regularización}{subsubsection.2.3.2.2}{}}
\citation{li2015cs231n}
\citation{nielsen2015neural}
\citation{li2015cs231n}
\citation{srivastava2014dropout}
\citation{baldi2014dropout}
\citation{li2015cs231n}
\citation{zou2005regularization}
\citation{li2015cs231n}
\citation{arora2015deep}
\citation{hinton2012improving}
\citation{gonzalez1995redes}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Figura tomada de , donde se representa la anulaci\'on de las salidas de cada neurona donde se aplic\'o dropout.\relax }}{27}{figure.caption.14}}
\newlabel{fig:dropout}{{2.6}{27}{Figura tomada de , donde se representa la anulación de las salidas de cada neurona donde se aplicó dropout.\relax }{figure.caption.14}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Red neuronal est\'andar}}}{27}{subfigure.6.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Luego de aplicar Dropout}}}{27}{subfigure.6.2}}
\citation{bishop2006pattern}
\citation{haykin2004comprehensive}
\citation{li2015cs231n}
\citation{erhan2010does}
\citation{bengio2009learning}
\citation{glorot2010understanding}
\citation{bengio2009learning}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Aprendizaje no supervisado}{28}{subsection.2.3.3}}
\newlabel{cap2:subsec:no-supervisado}{{2.3.3}{28}{Aprendizaje no supervisado}{subsection.2.3.3}{}}
\GLX@entry{PCA}{n}{acr}{a}{28}
\citation{hinton2006reducing}
\citation{marc2007efficient}
\citation{vincent2008extracting}
\citation{kingma2013auto}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Arquitectura b\'asica de un autocodificador.\relax }}{29}{figure.caption.15}}
\newlabel{fig:autoencoder_arq}{{2.7}{29}{Arquitectura básica de un autocodificador.\relax }{figure.caption.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.4}Autocodificadores}{29}{subsection.2.3.4}}
\newlabel{cap2:subsec:autoencoder}{{2.3.4}{29}{Autocodificadores}{subsection.2.3.4}{}}
\GLX@entry{AE}{n}{acr}{a}{29}
\citation{bengio2009learning}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Construcci\'on de un autocodificador apilado.\relax }}{30}{figure.caption.16}}
\newlabel{fig:stacked-autoencoder}{{2.8}{30}{Construcción de un autocodificador apilado.\relax }{figure.caption.16}{}}
\GLX@entry{SAE}{n}{acr}{a}{30}
\citation{bengio2009learning}
\@setckpt{Capitulos/01Capitulo2}{
\setcounter{page}{32}
\setcounter{equation}{26}
\setcounter{enumi}{2}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{1}
\setcounter{chapter}{2}
\setcounter{section}{3}
\setcounter{subsection}{4}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{8}
\setcounter{table}{4}
\setcounter{pgfpie@explodeLength}{0}
\setcounter{pgfpie@colorLength}{0}
\setcounter{pgfpie@sliceLength}{0}
\setcounter{float@type}{16}
\setcounter{algorithm}{0}
\setcounter{ALG@line}{0}
\setcounter{ALG@rem}{0}
\setcounter{ALG@nested}{0}
\setcounter{ALG@Lnr}{2}
\setcounter{ALG@blocknr}{10}
\setcounter{ALG@storecount}{0}
\setcounter{ALG@tmpcounter}{0}
\setcounter{parentequation}{0}
\setcounter{ContinuedFloat}{0}
\setcounter{KVtest}{0}
\setcounter{subfigure}{0}
\setcounter{subfigure@save}{2}
\setcounter{lofdepth}{1}
\setcounter{subtable}{0}
\setcounter{subtable@save}{0}
\setcounter{lotdepth}{1}
\setcounter{lstnumber}{1}
\setcounter{NAT@ctr}{0}
\setcounter{Item}{7}
\setcounter{Hfootnote}{6}
\setcounter{bookmark@seq@number}{35}
\setcounter{lstlisting}{0}
\setcounter{section@level}{0}
}
