%---------------------------------------------------------------------
%
%                          Capítulo 4
%
%---------------------------------------------------------------------

\chapter{Evaluación de desempeño}


\begin{FraseCelebre}
	\begin{Frase}
		Son nuestras elecciones las que muestran lo que somos, mucho más que nuestras habilidades.
	\end{Frase}
	\begin{Fuente}
		J.K. Rowling
	\end{Fuente}
\end{FraseCelebre}

\begin{resumen}
En este capítulo se describen las acciones ejecutadas para validar el correcto funcionamiento del motor de procesamiento y de la aplicación. Para ello, se siguieron distintos protocolos donde se definieron experimentos y validaciones sobre ciertas funcionalidades desarrolladas en este trabajo. Se detallan los recursos utilizados y las configuraciones implementadas sobre ellos para llevar a cabo estas tareas de evaluación.
\end{resumen}

\section{Conjuntos de datos para experimentación}

Con el objetivo de validar la utilidad y potencialidad del software, se define un conjunto de datos de prueba compuesto por diversas imágenes que provienen de fuentes diferentes y bajo normativas distintas. La primera de ellas consiste en la carpeta de imágenes de WhatsApp del ejecutor del proyecto, que contando con un total de 1600 imágenes aproximadamente, se considera representativa para cualquier usuario promedio. La segunda, 2000 imágenes pertenecientes al portal de internet 9GAG\footnote{\url{https://9gag.com/}}, sitio donde la comunidad partícipe sube imágenes de todo tipo de temática, todos los días. Por último, se utilizó también una base de datos denominada VOC\footnote{\url{http://host.robots.ox.ac.uk/pascal/VOC}}, la cual cuenta con diversos grupos de imágenes estandarizadas y se utiliza para medir algoritmos de clasificación de imágenes en diferentes competencias que se realizan año a año, sumarizando más de 17.000 imágenes. 

Si bien desde la última fuente de datos (VOC) es de donde se obtienen la mayoría de las imágenes que componen el conjunto para la experimentación, la realidad es que dicho conjunto es bastante genérico y puede no reflejar de manera correcta el contexto para el cual debe ser evaluado el motor. Allí es donde las 1600 imágenes de la carpeta de WhatsApp del ejecutor del proyecto como las 2000 imágenes recolectadas del sitio 9GAG toman relevancia. La primera de ellas intenta reflejar aquellas imágenes que un usuario ``normal'' recibe en el día a día en su teléfono, mientras que con la segunda se quiere evaluar la respuesta del motor ante un tipo de imagen muy famosa a la hora de ser enviada de un dispositivo a otro, que son las de tipo ``memes'' \footnote{\url{https://tecnologia-informatica.com/que-es-un-meme-como-hacerlos/}}.

Sumando todos los directorios, se contabilizan más de 19.000 imágenes pertenecientes a la base de datos de prueba.

%-------------------------------------------------------------------
\section{Protocolo de Experimentación}
%-------------------------------------------------------------------
\label{cap2:sec:experimentos}
El objetivo de esta sección es mostrar las pruebas que fueron ejecutadas sobre el motor de procesamiento, con el fin de validar que la calidad de agrupamiento de imágenes obtenida en su uso es aceptable como para ser de utilidad en la tarea de organización de las mismas. Dado que no se tiene como objetivo tener un desempeño específico, en términos de la calidad de clustering, se establece que no es necesario realizar un análisis que se compare o compita con el estado del arte en dicha tarea, ya que el motor de procesamiento no pretende más que sugerir grupos de imágenes que el usuario puede incluso modificar.

Como fue definido en la Especificación de Requisitos del Software (ERS), la experimentación abarcó diferentes aspectos:

\begin{itemize}
%	\item \underline{Datos:} se utilizaron imágenes obtenidas de las diferentes bases de datos definidas con anterioridad, como lo son:
%		\begin{itemize}
%			\item Carpeta de imágenes de WhatsApp del ejecutor del proyecto, obtenidas entre febrero y septiembre de 2017.
%			
%			\item Imágenes descargadas del sitio 9GAG (con el objetivo de detectar posibles imágenes catalogadas como ``memes'').
%			
%			\item Base de datos VOC, muy popular ya que cuenta con diversos grupos de imágenes proveniente de distintas categorías, utilizadas para medir algoritmos de clasificación de imágenes en diferentes competencias.
%		\end{itemize}
	
	\item \underline{Métricas:} debido a que los datos de prueba se encuentran relacionados a clases (e.g perro, memes, comida, etc.), se aprovechó dicha información para poder validar los experimentos de manera supervisada, planteando un problema de clasificación para poder considerar medidas como la tasa de aciertos en el análisis y complementar a las medidas de calidad de los clusters en la evaluación del desempeño.
	
%	La tarea que se realizó para poder clasificar a las imágenes, una vez que se consigue la sugerencia de organización por parte del proceso, fue obtener la moda de las clases comprendidas por cada conjunto resultado. Luego, a partir de una conglomeración o unión de aquellos grupos donde la búsqueda anterior arroja que pertenecen a la misma clase, se obtienen tantos grupos ``resultado'' como clases ``reales'' existen, y a partir de allí, se está en condiciones de llevar a cabo las diferentes medidas de clasificación y agrupamiento que se listan a continuación:

	\begin{figure}[t]
		\begin{center}
			\includegraphics[width=0.8\textwidth]%
			{Imagenes/Bitmap/conglomerado}
			\caption{Tarea realizada para poder obtener métricas de clasificación y clustering}
			\label{fig:conglomerado}
		\end{center}
	\end{figure}
	
	La tarea que se realizó para poder clasificar a las imágenes, una vez que se consigue la sugerencia de organización por parte del proceso, fue obtener la moda de las clases comprendidas por cada conjunto resultado. A partir de allí, cada grupo queda representado por una clase, por lo que se realiza una unión entre aquellos grupos que fueran representados por la misma, en caso de que este escenario existiera. Desde aquí, se cuenta con la misma cantidad de grupos ``resultado'' como grupos ``reales'' existen (los utilizados en un comienzo para la experimentación), para un mejor entendimiento ver Figura \ref{fig:conglomerado}. Por lo tanto, ya se está en condiciones de llevar adelante las medidas de clasificación y agrupamiento que se listan a continuación:
	
	
		\begin{itemize}
			\item  Las métricas elegidas para medir el desempeño de \underline{Clasificación} por parte del motor son \cite{sokolova2009systematic}:
				\begin{itemize}
					\item \textbf{Precision:} ratio entre el número de imágenes clasificadas de manera correcta para una clase sobre todas las imágenes clasificadas para esa clase (tanto correctas como incorrectas): $$Precision = \frac{tp}{tp + fp}$$
					
					\item \textbf{Recall:} ratio que representa el número de imágenes clasificadas de manera correcta sobre el total de imágenes que componen esa clase: $$Recall = \frac{tp}{tp + fn}$$
					
					\item \textbf{F1-Score:} calculado como la media armónica de los valores de ``precision'' y ``recall'' en la clasificación, extendido para soportar múltiples clases mediante ``macro-averaging''. El valor resultante varía entre 0 (clasificación pésima) y 1 (clasificación perfecta): $$F_{1} = 2 * \frac{precision * recall}{precision + recall}$$
					
					\item \textbf{Accuracy:} calculada como la exactitud de la clasificación, dada por la cantidad de aciertos sobre el total. El valor resultante varía entre 0 (clasificación pésima) y 1 (clasificación perfecta).
				\end{itemize}
			\item Para poder tener noción sobre qué tan bien se obtienen los diferentes grupos, las métricas de \underline{Clustering} elegidas son \cite{rosenberg2007v}:
				\begin{itemize}
					\item \textbf{Sorensen-Dice:} Este coeficiente estadístico fue seleccionado como indicador ya que puede ser interpretado como una medida cuantitativa sobre el resultado final del agrupamiento, comparando la similitud de cada clase ``real'' contra la clase ``resultante'' que más se le parezca. La operación que realiza para poder medir qué tan parecidos son dos conjuntos es la media armónica de la proporción o ratio que existe entre ellos, arrojando un número entre 0 y 1, siendo 0 un pobre resultado de agrupamiento y 1 el mejor que se pueda alcanzar \cite{meyer2004comparison}.
					
					\item \textbf{Silhouette:} medida de cuán similares son los ítems dentro de un cluster (cohesión) comparados con los de otros clusters (separación). El valor resultante varía entre -1 (clustering pésimo) y 1 (clustering perfecto), donde un valor de 0 indica solapamiento entre clusters \cite{rousseeuw1987silhouettes}. 
				\end{itemize}
		\end{itemize}
%	\item \underline{Configuraciones:} en base a un protocolo de pruebas ejecutado durante la etapa de desarrollo y especificado en la ERS, se llegó a la conclusión de que la configuración que dá mejores resultados es la definida en el capítulo anterior:
%	\begin{itemize}
%		\item Potencia de expansión: 2
%		\item Potencia de inflación: 3
%		\item Máxima cantidad de iteraciones: 100
%		\item 
%	\end{itemize}
	\item \underline{Desempeño computacional:} se midió el tiempo utilizado por cada prueba ejecutada. Los dispositivos móviles con los que se contó para realizar la experimentación son:
		\begin{itemize}
			\item Dispositivo 1: Motorola Moto G4 PLUS XT1641 32GB (Gama media/baja)
			\item Dispositivo 2: Xiaomi Redmi Note 4 64GB (Gama media/alta)
			\item Dispositivo 3: Samsung Galaxy S9 (Gama alta)
		\end{itemize}
%	\item \underline{Criterio de aprobación:} Dado que en una aplicación real la valoración de un cluster puede ser subjetiva (es decir, el juicio depende mucho del usuario final), los niveles de aceptación en las métricas se relajan dado que el clustering final obtenido pretende ser únicamente una sugerencia de organización que el usuario puede modificar con menor esfuerzo que si lo hiciera con el conjunto total de imágenes. Por lo tanto, se establecen los siguientes criterios:
%		\begin{itemize}
%			\item Métricas:
%				\begin{itemize}
%					\item F1-Score > 0.4
%					\item Accuracy > 1 / (cantidad de clases tratadas)
%					\item Sorensen-Dice > 0.4
%					\item Silhouette > 0 
%				\end{itemize}
%%			\item Valoración subjetiva del clustering obtenido: para saber si le es útil al usuario en un caso real (entre 1 y 5 estrellas). Realizado por hasta 3 usuarios distintos.
%			\item En cuanto al desempeño en términos computacionales, se espera que el procesamiento total no lleve más de 150 segundos para las pruebas normales (entre 2 y 250 imágenes) y no más de 300 segundos para las pruebas de escalabilidad (entre 250 y 1000 imágenes).
%		\end{itemize}
\end{itemize}

\subsection{Pruebas realizadas}

A continuación se presentan pruebas que fueron aplicadas sobre el motor de procesamiento de imágenes. Las mismas son distintivas entre ellas y muestran diferentes casos de aplicación que podrían proporcionar los usuarios. Todas fueron realizadas con las configuraciones descriptas en el capítulo anterior, donde se explicó el paso a paso por el que transitan las imágenes dentro del motor. La decisión de utilizar todos esos parámetros se debe a un protocolo de experimentación realizado durante la etapa de desarrollo, donde se realizaron diferentes pruebas modificándolos a fin de obtener la configuración que mejor se ajuste a la problemática planteada en esta tesis. A continuación, se presenta un nuevo conjunto de pruebas definidas con otro lote de imágenes, y así validar la performance alcanzada con dichos parámetros. %Estas pruebas pueden verificarse en la ERS entregada durante los diferentes informes de avance.

Resulta \textbf{importante} recordar que no fue necesario entrenar la CNN utilizada para la extracción de características de las imágenes, ya que la misma fue adquirida con sus coeficientes ajustados y listos para utilizar, por lo que los datos pasan por ella y luego se realiza el clustering.

\subsubsection{Prueba 1}

La primer prueba se realizó con un total de 184 imágenes, distribuidas en 6 clases diferentes. Lo que se quiso visualizar aquí es como se comporta la aplicación en una situación ``normal'' de uso, donde las imágenes a procesar no son demasiadas y las clases se encuentran bien distribuidas. 

El \textbf{accuracy} logrado para esta primera prueba es de un 83.69\%. Además, como se puede observar en la Tabla \ref{tab:prueba1}, los resultados respecto a las demás medidas de clasificación fueron satisfactorios. Para poder obtener una entendimiento global de las mismas, se toma el promedio de cada una de ellas (\textit{Precision, Recall y F1-Score}). Este método se denomina ``macro-averaging'' y es útil cuando se desea saber cómo funcionan los sistemas en general para todos los conjuntos de datos \cite{macroaveraging}.

\begin{table}[t]
	\begin{center}
		\caption{Resultados de la prueba 1  - Clasificación.}
		\label{tab:prueba1}
		\begin{adjustbox}{max width=\textwidth}
			\begin{tabular}{l|c|c|c|c}
				\hline
				\hline
				\textbf{Categoría} & \textbf{Cant. Ejemplos} & \textbf{Precision[\%]} & \textbf{Recall[\%]} & \textbf{F1-Score[\%]} \\
				\hline
				Avión & 25 & 95.83 & 95.83 & 95.83\\
				
				Computadora & 35 & 82.85 & 85.29 & 84.06\\
				
				Documento & 50 & 86.53 & 91.83 & 89.11\\
				
				Bebida & 30 & 66.67 & 62.07 & 64.29\\
				
				Fiestas & 33 & 88.89 & 1 & 94.12\\
				
				Estadio & 11 & 70 & 70 & 70\\
				
				Macro-averaging &  & \textbf{81.79} & \textbf{84.17} & \textbf{82.90}\\
				\hline	
			\end{tabular}
		\end{adjustbox}
	\end{center}
\end{table}

En términos de \textit{clustering} se obtuvieron buenas métricas, por lo que se puede decir que el motor de procesamiento agrupó a las imágenes de una manera aceptable. Las mismas, se pueden observar a continuación:

\begin{itemize}
	\item \textbf{Silhouette:} 0.2522
	\item \textbf{Sorensen-Dice:} 0.8290
\end{itemize}

En cuanto a los tiempos de proceso, se puede ver en la Tabla \ref{tab:tiempo1} cómo van disminuyendo, conforme la gama del dispositivo va aumentando. Esto está directamente relacionado a los recursos (hardware) con los que cuenta cada uno. 

\begin{table}[h!]
	\begin{center}
		\caption{Tiempos de proceso - Prueba 1.}
		\label{tab:tiempo1}
		\begin{adjustbox}{max width=\textwidth}
			\begin{tabular}{l|c}
				\hline
				\hline
				\textbf{Dispositivo} & \textbf{Tiempo de proceso (segundos)}\\
				\hline
				Moto G4 Plus & 142.75\\
				
				Xiaomi Redmi 4 & 88.31\\
				
				Samsung Galaxy S9 & 35.86\\
				\hline
			\end{tabular}
		\end{adjustbox}
	\end{center}
\end{table}

\hfil

\subsubsection{Prueba 2}

En una segunda prueba se utilizaron un total de 298 imágenes, pertenecientes a 5 clases distintas. El objetivo de este experimento fue observar cómo se comporta el motor ante un aumento considerado en la cantidad de imágenes a procesar, además de que se encuentren muchas más imágenes de una categoría con respecto a las otras (clase ``Screenshots''). 

El \textit{accuracy} logrado es de 55.7\% y como se puede ver en la Tabla \ref{tab:prueba2}, si bien se obtuvieron métricas aceptables en términos de clasificación, hubo una baja considerable en todas las medidas respecto a la prueba anterior. Por ejemplo, se observa que la categoría ``Memes'' es la que obtiene las medidas más bajas. Al revisar el resultado, se encontraron varias imágenes de esta clase agrupadas con imágenes pertenecientes a la categoría ``Screenshots''.

\begin{table}[h!]
	\begin{center}
		\caption{Resultados de la prueba 2  - Clasificación.}
		\label{tab:prueba2}
		\begin{adjustbox}{max width=\textwidth}
			\begin{tabular}{l|c|c|c|c}
				\hline
				\hline
				\textbf{Categoría} & \textbf{Cant. Ejemplos} & \textbf{Precision[\%]} & \textbf{Recall\%} & \textbf{F1-Score\%} \\
				\hline
				
				Gato & 15 & 76.47 & 92.86 & 86.87\\
				
				Computadora & 40 & 54.34 & 64.10 & 58.82\\
				
				Bebida & 30 & 50 & 58.62 & 53.96\\
				
				Memes & 68 & 37.87 & 37.31 & 37.59\\
				
				Screenshots & 145 & 63.70 & 59.72 & 61.64\\
				
				Macro-averaging &  & \textbf{56.48} & \textbf{62.52} & \textbf{59.18}\\
				\hline
			\end{tabular}
		\end{adjustbox}
	\end{center}
\end{table}

\hfil

Las medidas de \textit{clustering} obtenidas son las siguientes: 

\begin{itemize}
	\item \textbf{Silhouette:} 0.0101
	\item \textbf{Sorensen-Dice:} 0.5879
\end{itemize}

Se puede observar que la \textit{Silhouette} en general fue baja, ya que el algoritmo creó muchos grupos de 2 o 3 imágenes, haciendo que esta métrica esté muy cercana al valor 0 (solapamiento entre grupos). Vale aclarar que dentro de estos \textit{clusters} chicos, las imágenes tenían mucha relación entre sí, por lo que subjetivamente se podría considerar como una buena agrupación.

Otro punto a destacar, es cómo al aumentar la cantidad de imágenes a procesar, el tiempo en los celulares de mayor gama se reduce casi en un 50\% respecto al celular de gama media/baja.

\begin{table}[h!]
	\begin{center}
		\caption{Tiempos de proceso - Prueba 2.}
		\label{tab:tiempo2}
		\begin{adjustbox}{max width=\textwidth}
			\begin{tabular}{l|c}
				\hline
				\hline
				\textbf{Dispositivo} & \textbf{Tiempo de proceso (segundos)}\\
				\hline
				Moto G4 Plus & 215.24\\
				
				Xiaomi Redmi 4 & 138.20\\
				
				Samsung Galaxy S9 & 62.25\\
				\hline
			\end{tabular}
		\end{adjustbox}
	\end{center}
\end{table}

\hfil

\subsubsection{Prueba 3}

Por último, se muestra una prueba donde el objetivo fue elevar aún más el número de imágenes y clases, y así poder medir la escalabilidad del motor y su comportamiento en diferentes dispositivos. Las clases utilizadas fueron 10 con un total de 500 imágenes y como se puede observar en la Tabla \ref{tab:prueba3}, las métricas obtenidas en cuanto a clasificación por cada una de las categorías utilizadas son buenas, logrando además un \textit{accuracy} global de 63\%. 

Es necesario aclarar que algunas obtuvieron un F1-Score cercano al 50\%, como por ejemplo la clase ``Memes''. Lo que sucede allí, al observar las imágenes utilizadas en la experimentación, es que en esta categoría en realidad existen imágenes de cualquier tipo y temática, por lo que el indicio de que esas imágenes deben pertenecer a dicha categoría es bastante bajo.

\begin{table}[h!]
	\begin{center}
		\caption{Resultados de la prueba 1  - Clasificación.}
		\label{tab:prueba3}
		\begin{adjustbox}{max width=\textwidth}
			\begin{tabular}{l|c|c|c|c}
				\hline
				\hline
				\textbf{Categoría} & \textbf{Cant. Ejemplos} & \textbf{Precision[\%]} & \textbf{Recall[\%]} & \textbf{F1-Score[\%]} \\
				\hline
				
				Avión & 25 & 57.69 & 62.50 & 59.99\\
				
				Bicicleta & 50 & 56.25 & 73.46 & 63.71\\
				
				Pájaro & 35 & 71.79 & 82.35 & 76.71\\
				
				Bus & 30 & 65.63 & 72.41 & 68.85\\
				
				Automóvil & 70 & 57.40 & 44.93 & 50.40\\
				
				Gato & 15 & 81.25 & 92.85 & 86.66\\
				
				Computadora & 51 & 54.90 & 56 & 55.44\\
				
				Perro & 101 & 76.57 & 85 & 80.57\\
				
				Memes & 90 & 55.55 & 44.94 & 49.68\\
				
				Fiestas & 33 & 51.42 & 56.25 & 53.73\\
				
				Macro-averaging &  & \textbf{62.84} & \textbf{67.07} & \textbf{64.59}\\
				\hline
			\end{tabular}
		\end{adjustbox}
	\end{center}
\end{table}

\hfil

La Imagen \ref{fig:ninegag-to-dog} representa un ejemplo que pertenece a la categoría ``Memes'', pero la misma contiene la cabeza de un perro, por lo que se supone que el proceso a la hora de caracterizarla toma como más relevante esta información (superando a los dedos, e incluso al texto en  la parte de arriba) y en el resultado final se visualiza junto a un grupo de imágenes pertenecientes a la categoría ``Perro''. Como este ejemplo, pueden existir muchas imágenes donde la clase es bastante ambigua. En efecto, una imagen podría pertenecer a muchas categorías a la vez, por lo que ocasionalmente el motor terminará agrupándola con imágenes que quizás para el usuario no tienen mucha relación. Allí es donde se detecta la necesidad de contar en la aplicación con herramientas que le permitan interactuar y modificar el resultado sugerido por el procesamiento.


\begin{figure}[!hb]
	\begin{center}
		\includegraphics[width=0.4\textwidth]%
		{Imagenes/Bitmap/ninegag_65}
		\caption{Ejemplo de una imagen perteneciente a la categoría ``Memes''.}
		\label{fig:ninegag-to-dog}
	\end{center}
\end{figure}

\hfil

En relación a las métricas de clustering, así como sucedió con las de clasificación, se pueden considerar como positivas cuando se escala a la aplicación tanto hacia una mayor diversidad de grupos como a una cantidad más grandes de imágenes a procesar. Las mismas se pueden ver a continuación:

\begin{itemize}
	\item \textbf{Silhouette:} 0.1581
	\item \textbf{Sorensen-Dice:} 0.639
\end{itemize}

El inconveniente se encuentra en el tiempo de proceso, ya que fue bastante largo ($\approx$ 9 minutos para el dispositivo 1). Es por ello que fue necesario establecer un límite en relación a la cantidad de imágenes procesadas - tiempo, ya que para dispositivos gama baja/media es demasiado el tiempo que consume.

\begin{table}[h!]
	\begin{center}
		\caption{Tiempos de proceso - Prueba 3.}
		\label{tab:tiempo3}
		\begin{adjustbox}{max width=\textwidth}
			\begin{tabular}{l|c}
				\hline
				\hline
				\textbf{Dispositivo} & \textbf{Tiempo de proceso (segundos)}\\
				\hline
				Moto G4 Plus & 515.38\\
				
				Xiaomi Redmi 4 & 335.91\\
				
				Samsung S9 & 170.25\\
				\hline
			\end{tabular}
		\end{adjustbox}
	\end{center}
\end{table}

\hfil

\subsubsection{Prueba 4}

La finalidad de esta prueba es mostrar los resultados que se obtienen si solamente se usa la matriz de afinidad gramatical o la matriz de afinidad según \textit{embeddings}, con el objetivo de comparar contra los resultados obtenidos al ponderar ambas matrices (como se realiza en el proceso normal de la aplicación), y así justificar el uso de ambas maneras de obtener características por parte de las imágenes.

Las pruebas realizadas a continuación utilizan los mismos datos que la Prueba Nº 1 (ver Tabla \ref{tab:prueba1}), sólo qué en una primera instancia el proceso es llevado a cabo únicamente por la matriz de afinidad gramatical, y en una segunda instancia se utiliza únicamente la matriz de afinidad según \textit{embeddings}.

En el primero experimento, el \textit{accuracy} obtenido es de 57.6\%. En la Tabla \ref{tab:prueba4-aff-gra} se pueden ver las demás métricas en términos de clasificación, cuando solamente se utiliza la matriz de afinidad gramatical. Es notorio el descenso en el rendimiento, comparado con la Prueba Nº 1 (se reducen en un 30\% aproximadamente). 

\begin{table}[h!]
	\begin{center}
		\caption{Resultados de la prueba 1  - Clasificación - Afinidad Gramatical.}
		\label{tab:prueba4-aff-gra}
		\begin{adjustbox}{max width=\textwidth}
			\begin{tabular}{l|c|c|c|c}
				\hline
				\hline
				\textbf{Categoría} & \textbf{Cant. Ejemplos} & \textbf{Precision[\%]} & \textbf{Recall[\%]} & \textbf{F1-Score[\%]} \\
				\hline
				
				Avión & 25 & 91.30 & 87.50 & 89.36\\

				Computadora & 35 & 50 & 47.05 & 48.48\\

				Documento & 50 & 55.17 & 65.30 & 59.81\\

				Bebida & 30 & 57.14 & 55.17 & 56.14\\

				Fiestas & 33 & 48.48 & 50 & 49.23\\

				Estadio & 11 & 50 & 50 & 50\\

				Macro-averaging &  & \textbf{58.68} & \textbf{59.17} & \textbf{58.83}\\
				\hline
			\end{tabular}
		\end{adjustbox}
	\end{center}
\end{table}

Por otra parte, las métricas que representan qué tan bien se dividieron los grupos de imágenes fueron mucho más bajas que las obtenidas cuando se utiliza una ponderación de ambas matrices de afinidad:

\begin{itemize}
	\item \textbf{Silhouette:} 0.001
	\item \textbf{Sorensen-Dice:} 0.5883
\end{itemize}

Siguiendo ahora con la prueba utilizando únicamente la matriz de afinidad según \textit{embeddings}, se puede observar que en la Tabla \ref{tab:prueba4-aff-emb} las métricas obtenidas son aceptables, pero tampoco se comparan con aquellas logradas en la prueba Nº 1. Para esta ocasión, el \textit{accuracy} obtenido es de 68.91\%. 

Un dato no menor es el alto porcentaje de clasificación que obtuvo la clase ``Fiestas''. Al revisar dichas imágenes, fueron todas capturadas en un ambiente oscuro, con luces brillantes y de colores, por lo que tiene sentido que el motor las caracterice de manera similar. 

\begin{table}[h!]
	\begin{center}
		\caption{Resultados de la prueba 1  - Clasificación - Afinidad según \textit{embeddings}.}
		\label{tab:prueba4-aff-emb}
		\begin{adjustbox}{max width=\textwidth}
			\begin{tabular}{l|c|c|c|c}
				\hline
				\hline
				\textbf{Categoría} & \textbf{Cant. Ejemplos} & \textbf{Precision[\%]} & \textbf{Recall[\%]} & \textbf{F1-Score[\%]} \\
				\hline
				
				Avión & 25 & 77.27 & 70.83 & 73.91\\

				Computadora & 35 & 72.22 & 38.23 & 50\\

				Documento & 50 & 67.16 & 91.83 & 77.58\\

				Bebida & 30 & 57.14 & 68.96 & 62.50\\

				Fiestas & 33 & 91.17 & 96.87 & 93.93\\

				Estadio & 11 & 62.50 & 50 & 55.55\\

				Macro-averaging &  & \textbf{71.24} & \textbf{59.17} & \textbf{69.46}\\
				\hline
			\end{tabular}
		\end{adjustbox}
	\end{center}
\end{table}

Al observar las métricas correspondientes al \textit{clustering}, se puede concluir que son satisfactorias, aunque para la \textit{Silhouette}, por ejemplo, la medida disminuye más de un 50\% respecto a la que se obtuvo en la Prueba Nº 1:

\begin{itemize}
	\item \textbf{Silhouette:} 0.1
	\item \textbf{Sorensen-Dice:} 0.6876
\end{itemize}

De todas maneras, igual a lo explicado en el experimento anterior, no alcanza a lograr los resultados que se obtienen cuando se utilizan ambas matrices como caracterización de las imágenes. 

\hfil

Se puede ver a partir de estos experimentos, que la propuesta de combinar ambas matrices de características permite mejorar significativamente los resultados respecto a utilizar sólo una de ellas. Incluso en un futuro, podrían estudiarse nuevas maneras de obtener características y ver como reacciona el motor al agregarlas al proceso. 

\section{Validación de la aplicación}

Con el objetivo de corroborar el correcto funcionamiento de todos los módulos que componen el sistema, verificando que actúan y responden según lo esperado, se definieron pruebas unitarias (mejor conocido en inglés como \textit{unit testing}), y un protocolo de validación donde se presentaron un conjunto de casos de prueba relacionadas a la experiencia de usuario. Todo será detallado a continuación.

\subsection{Pruebas unitarias}

De forma que las características de la aplicación sean validadas en términos
de funcionalidad, se procede a utilizar diferentes herramientas que permitan testear los módulos implementados. Esto es realizado con el fin de seguir buenas prácticas de ingeniería en software \cite{sommerville2007software}, que permitan desarrollar un producto que asegure cierta calidad en su integración y despliegue.

Las pruebas unitarias son una forma de comprobar el correcto funcionamiento de un módulo de forma aislada al resto de los componentes. Para ello se define un escenario para ejecutar las acciones de ese módulo en forma separada, y se corrobora obtener un cierto comportamiento esperado en la salida de cada una de ellas \cite{learninspy2016tesis}. Mediante la utilización de los frameworks \textbf{JUnit}\footnote{\url{https://junit.org}}, \textbf{Espresso}\footnote{\url{https://developer.android.com/training/testing/espresso/}} y \textbf{PowerMock}\footnote{\url{https://github.com/powermock/powermock}}, se llevaron adelante las pruebas de la aplicación de forma automatizada. Gracias a ellos se fue probando de a pequeñas porciones de código. Para esto se estableció un escenario posible con datos de entrada, ejecutando las acciones de cada módulo y corroborando el comportamiento esperado en las salida de cada uno de los casos.

\subsection{Protocolo de validación}

Con el objetivo de validar que todos los módulos que componen la aplicación responden y actúan según lo esperado, se definieron un conjunto de pruebas a realizar sobre la aplicación finalizada y aquí se muestran los resultados:

\begin{itemize}
	\item \textbf{\underline{Prueba Nº 1}}
	\begin{itemize}
		\item \textbf{Sujeto:} Ejecutor del proyecto
		\item \textbf{Tarea:} Seleccionar ícono de ingreso al sistema dentro del menú Android.
		\item \textbf{Criterio de aprobación:} Ingreso a la aplicación de forma directa sin ningún tipo de publicidad o presentación.
		\item \textbf{Estado:} APROBADO
		\item \textbf{Comentarios:} Una vez que se aprieta el ícono representativo, se ingresa a la aplicación sin demoras ni errores.
	\end{itemize}
	\item \textbf{\underline{Prueba Nº 2}}
	\begin{itemize}
		\item \textbf{Sujeto:} Ejecutor del proyecto
		\item \textbf{Tarea:} Acceder al menú de elección de directorios a procesar.
		\item \textbf{Criterio de aprobación:} Acceso al explorador de archivos, pudiendo visualizar el contenido dentro de cada carpeta.
		\item \textbf{Estado:} APROBADO
		\item \textbf{Comentarios:} Se brinda la opción de seleccionar el directorio a procesar. Se visualizan directorios (en caso de que existan) dentro de la carpeta seleccionada, pero no su respectivo contenido (e.g imágenes, documentos, etc.)
	\end{itemize}
	\item \textbf{\underline{Prueba Nº 3}}
	\begin{itemize}
		\item \textbf{Sujeto:} Ejecutor del proyecto
		\item \textbf{Tarea:} Verificar estado de procesamiento de las imágenes durante la ejecución.
		\item \textbf{Criterio de aprobación:} El sistema muestra en todo momento el grado de avance del procesamiento, calculado en base a la cantidad de imágenes procesadas y la cantidad total de imágenes a procesar.
		\item \textbf{Estado:} APROBADO
		\item \textbf{Comentarios:} Durante el procesamiento de las imágenes se puede visualizar el porcentaje de procesamiento realizado en cada momento.
	\end{itemize}
	\item \textbf{\underline{Prueba Nº 4}}
	\begin{itemize}
		\item \textbf{Sujeto:} Ejecutor del proyecto
		\item \textbf{Tarea:} Verificar informe de finalización de procesamiento de imágenes por parte del sistema.
		\item \textbf{Criterio de aprobación:} Deberá indicar el estado de finalización (éxito o error). En caso de que haya finalizado exitosamente, a continuación deberá presentar el menú de administración del resultado.
		\item \textbf{Estado:} APROBADO
		\item \textbf{Comentarios:} Una vez finalizado el procesamiento, el sistema muestra la sugerencia de organización de las imágenes si finaliza de manera exitosa. En caso de finalizar con algún tipo de error, vuelve todo hacia atrás y solicita que el proceso vuelva a ejecutarse.
	\end{itemize}
	\item \textbf{\underline{Prueba Nº 5}}
	\begin{itemize}
		\item \textbf{Sujeto:} Ejecutor del proyecto
		\item \textbf{Tarea:} Probar las diferentes opciones de administración de imágenes y directorios sugeridos por el resultado.
		\item \textbf{Criterio de aprobación:} La utilización de dichas opciones debe responder de manera fluida y realizar las tareas especificadas. Debe informar el éxito de cada tarea realizada de manera dinámica y rápida.
		\item \textbf{Estado:} APROBADO
		\item \textbf{Comentarios:} Se corroboró que la aplicación responda adecuadamente con las distintas opciones de administración de directorios disponibles (e.g. renombrar, mover, eliminar, etc)
	\end{itemize}
	\item \textbf{\underline{Prueba Nº 6}}
	\begin{itemize}
		\item \textbf{Sujeto:} Ejecutor del proyecto
		\item \textbf{Tarea:} Seleccionar el botón de confirmar el resultado final.
		\item \textbf{Criterio de aprobación:} El sistema deberá brindar al usuario la opción de mover de manera permanente o copiar el resultado final.
		\item \textbf{Estado:} APROBADO
		\item \textbf{Comentarios:} La aplicación responde correctamente al presionar el botón confirmar, mostrando las diferentes opciones, ya sea copiar o mover el resultado final, o bien cancelar y volver a la pantalla anterior.
	\end{itemize}
	\item \textbf{\underline{Prueba Nº 7}}
	\begin{itemize}
		\item \textbf{Sujeto:} Ejecutor del proyecto
		\item \textbf{Tarea:} Mover de manera permanente el resultado final hacia una nueva carpeta.
		\item \textbf{Criterio de aprobación:} La aplicación deberá mover las imágenes desde su ubicación original hacia la nueva carpeta generada.
		\item \textbf{Estado:} APROBADO
		\item \textbf{Comentarios:} Los resultados se encuentran en la ubicación esperada luego de confirmarlos, y son eliminados de su ubicación anterior.
	\end{itemize}
	\item \textbf{\underline{Prueba Nº 8}}
	\begin{itemize}
		\item \textbf{Sujeto:} Ejecutor del proyecto
		\item \textbf{Tarea:} Copiar el resultado final hacia una nueva carpeta.
		\item \textbf{Criterio de aprobación:} La aplicación deberá copiar (sin eliminar las imágenes desde su ubicación original) hacia la nueva carpeta generada.
		\item \textbf{Estado:} APROBADO
		\item \textbf{Comentarios:} La aplicación copia los archivos de manera correcta a la ubicación indicada una vez que los resultados son confirmados.
	\end{itemize}
	\item \textbf{\underline{Prueba Nº 9}}
	\begin{itemize}
		\item \textbf{Sujeto:} Ejecutor del proyecto
		\item \textbf{Tarea:} Seleccionar el botón de descartar el resultado final.
		\item \textbf{Criterio de aprobación:} La ubicación de cada imagen deberá permanecer inalterada y en el estado original previo a la utilización de la aplicación. Informar al usuario el éxito de la operación.
		\item \textbf{Estado:} APROBADO
		\item \textbf{Comentarios:} El estado original de las imágenes procesadas se conserva correctamente luego de descartar un resultado de agrupamiento.
	\end{itemize}
\end{itemize}