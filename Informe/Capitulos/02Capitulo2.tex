%---------------------------------------------------------------------
%
%                          Capítulo 4
%
%---------------------------------------------------------------------

\chapter{Evaluación de desempeño}


\begin{FraseCelebre}
	\begin{Frase}
		Son nuestras elecciones las que muestran lo que somos, mucho mas que nuestras habilidades.
	\end{Frase}
	\begin{Fuente}
		Albus Dumbledore
	\end{Fuente}
\end{FraseCelebre}

\begin{resumen}
En este capítulo se describen las acciones ejecutadas para validar el correcto funcionamiento del motor de procesamiento y de la aplicación. Para ello, se llevan adelante distintos protocolos donde se definieron experimentos y validaciones sobre ciertas funcionalidades desarrolladas en este trabajo. Se detallan los recursos utilizados y las configuraciones implementadas sobre ellos para llevar a cabo estas tareas de evaluación.
\end{resumen}

\section{Conjuntos de datos para experimentación}

Con el objetivo de validar la utilidad y potencialidad del software, se define un conjunto de base de datos de prueba compuesto por diversas imágenes que provienen de lugares diferentes y bajo normativas distintas. La primera de ellas consiste en la carpeta de imágenes de WhatsApp del ejecutor del proyecto, que contando con un total de 1600 imágenes aproximadamente, se considera representativa para cualquier usuario promedio. La segunda, 2000 imágenes pertenecientes al portal de internet 9GAG\footnote{\url{https://9gag.com/}}, sitio donde la comunidad participe sube imágenes de todo tipo de temática, todos los días. Por último, se utilizó también una base de datos denominada VOC\footnote{\url{http://host.robots.ox.ac.uk/pascal/VOC}}, la cual cuenta con diversos grupos de imágenes estandarizadas y se utiliza para medir algoritmos de clasificación de imágenes en diferentes competencias que se realizan año a año, sumarizando más de 17.000 imágenes.

Sumando todos los directorios, se contabilizan más de 19.000 imágenes pertenecientes a la base de datos de prueba.

%-------------------------------------------------------------------
\section{Protocolo de Experimentación}
%-------------------------------------------------------------------

El objetivo de esta sección es especificar las pruebas que fueron ejecutadas sobre el motor de procesamiento, con el fin de validar que la calidad de agrupamiento de imágenes obtenida en su uso es aceptable como para ser de utilidad en la tarea de organización de las mismas.

Como fue definido en la Especificación de Requisitos del Software (ERS), la experimentación abarcó diferentes aspectos:

\begin{itemize}
	\item \underline{Datos:} se utilizaron 959 imágenes, obtenidas de las diferentes bases de datos definidas con anterioridad, como lo son:
		\begin{itemize}
			\item Carpeta de imágenes de WhatsApp del ejecutor del proyecto, obtenidas entre febrero y septiembre de 2017: 649 imágenes.
			
			\item Imágenes descargadas del sitio 9GAG (con el objetivo de detectar posibles imágenes catalogadas como ``memes''): 100 imágenes.
			
			\item Base de datos VOC, muy popular ya que cuenta con diversos grupos de imágenes proveniente de distintas categorías, utilizadas para medir algoritmos de clasificación de imágenes en diferentes competencias: 210 imágenes.
		\end{itemize}
	
	\item \underline{Métricas:} debido a que los datos de prueba se encuentran relacionados a clases (e.g perro, memes, comida, etc.), se aprovechó dicha información para poder validar los experimentos de manera supervisada, planteando un problema de clasificación para poder considerar medidas como la tasa de aciertos en el análisis y complementar a las medidas de calidad de los clusters en la evaluación del desempeño.
	
	La tarea que se realizó para poder clasificar a las imágenes, una vez que se consigue la sugerencia de organización por parte del proceso, fue obtener la moda de las clases comprendidas por cada conjunto resultado. Luego, a partir de una conglomeración o unión de aquellos grupos donde la búsqueda anterior arroja que pertenecen a la misma clase, se obtienen tantos grupos ``resultado'' como clases ``reales'' existen, y a partir de allí, se está en condiciones de llevar a cabo las diferentes medidas de clasificación y agrupamiento que se listan a continuación:
		\begin{itemize}
			\item  Las métricas elegidas para medir de manera supervisada la \underline{Clasificación} por parte del motor son \cite{sokolova2009systematic}:
				\begin{itemize}
					\item \textbf{F1-Score:} computado como la media armónica de los valores de ``precision'' y ``recall'' en la clasificación, extendido para soportar múltiples clases mediante ``macro-averaging''. El valor resultante varía entre 0 (clasificación pésima) y 1 (clasificación perfecta).
					
					\item \textbf{Accuracy:} calculada como la exactitud de la clasificación, dada por la cantidad de aciertos sobre el total. El valor resultante varía entre 0 (clasificación pésima) y 1 (clasificación perfecta).
				\end{itemize}
			\item Para poder tener noción sobre qué tan bien se obtienen los diferentes grupos, las métricas de \underline{Clustering} elegidas son \cite{rosenberg2007v}:
				\begin{itemize}
					\item \textbf{Sorensen-Dice:} Este coeficiente estadístico fue seleccionado como indicador ya que puede ser interpretado como una medida cuantitativa sobre el resultado final del agrupamiento, comparando la similitud de cada clase ``real'' contra la clase ``resultante'' que más se le parezca. La operación que realiza para poder medir qué tan parecidos son dos conjuntos es la media armónica de la proporción o ratio que existe entre ellos, arrojando un número entre 0 y 1, siendo 0 un pobre resultado de agrupamiento y 1 el mejor que se pueda alcanzar \cite{meyer2004comparison}.
					
					\item \textbf{Silhouette:} medida de cuán similares son los ítems dentro de un cluster (cohesión) comparados con los de otros clusters (separación). El valor resultante varía entre -1 (clustering pésimo) y 1 (clustering perfecto), donde un valor de 0 indica solapamiento entre clusters \cite{rousseeuw1987silhouettes}. 
				\end{itemize}
		\end{itemize}
%	\item \underline{Configuraciones:} en base a un protocolo de pruebas ejecutado durante la etapa de desarrollo y especificado en la ERS, se llegó a la conclusión de que la configuración que dá mejores resultados es la definida en el capítulo anterior:
%	\begin{itemize}
%		\item Potencia de expansión: 2
%		\item Potencia de inflación: 3
%		\item Máxima cantidad de iteraciones: 100
%		\item 
%	\end{itemize}
	\item \underline{Desempeño computacional:} se midió el tiempo utilizado por cada prueba ejecutada. Los dispositivos móviles con los que se contó para realizar la experimentación son:
		\begin{itemize}
			\item Dispositivo 1: Motorola Moto G4 PLUS XT1641 32GB
			\item Dispositivo 2: Xiaomi Redmi Note 4 64GB
		\end{itemize}
	\item \underline{Criterio de aprobación:} Dado que en una aplicación real la valoración de un cluster puede ser subjetiva (es decir, el juicio depende mucho del usuario final), los niveles de aceptación en las métricas se relajan dado que el clustering final obtenido pretende ser únicamente una sugerencia de organización que el usuario puede modificar con menor esfuerzo que si lo hiciera con el conjunto total de imágenes. Por lo tanto, se establecen los siguientes criterios:
		\begin{itemize}
			\item Métricas:
				\begin{itemize}
					\item F1-Score > 0.4
					\item Accuracy > 1 / (cantidad de clases tratadas)
					\item Sorensen-Dice > 0.4
					\item Silhouette > 0 
				\end{itemize}
%			\item Valoración subjetiva del clustering obtenido: para saber si le es útil al usuario en un caso real (entre 1 y 5 estrellas). Realizado por hasta 3 usuarios distintos.
			\item En cuanto al desempeño en términos computacionales, se espera que el procesamiento total no lleve más de 150 segundos para las pruebas normales (entre 2 y 250 imágenes) y no más de 300 segundos para las pruebas de escalabilidad (entre 250 y 1000 imágenes).
		\end{itemize}
\end{itemize}

\textbf{Importante:} Dado que no se tiene como objetivo tener un desempeño específico, en términos de la calidad de clustering, se establece que no es necesario realizar un análisis que se compare o compita con el estado del arte en dicha tarea ya que el motor de procesamiento no pretende más que sugerir grupos de imágenes que el usuario puede incluso modificar.

\subsection{Pruebas realizadas}

A continuación se presentan pruebas que fueron aplicadas sobre el motor de procesamiento de imágenes. Las mismas son distintivas entre ellas y muestran diferentes casos de aplicación que podrían proporcionar los usuarios. Todas fueron realizadas con las configuraciones descriptas en el capítulo anterior donde se explicó el paso a paso por el que transitan las imágenes dentro del motor. La decisión de utilizar todos esos parámetros se debe a un protocolo de experimentación realizado durante la etapa de desarrollo, donde se realizaron diferentes pruebas modificándolos. A partir de allí se pudo notar que la configuraciones que mejor resultado arrojan son las elegidas. %Estas pruebas pueden verificarse en la ERS entregada durante los diferentes informes de avance.

La primer prueba se realizó con un total de 164 imágenes, distribuidas en 5 clases diferentes:
\begin{itemize}
	\item Computadora: 40 imágenes
	\item Documento: 50 imágenes
	\item Bebida: 30 imágenes
	\item Fiestas: 33 imágenes
	\item Estadio: 11 imágenes
\end{itemize} 

Lo que se quiso visualizar aquí es como se comporta la aplicación en una situación ``normal'' de uso, donde las imágenes a procesar no son demasiadas y las clases se encuentran bien distribuidas. Como se puede observar en la Tabla \ref{tab:prueba1}, los resultados fueron satisfactorios tanto para las métricas de clasificación, clustering y tiempo de proceso.

\begin{table}[h!]
	\begin{center}
		\caption{Resultados de la prueba 1.}
		\label{tab:prueba1}
		\begin{adjustbox}{max width=\textwidth}
			\begin{tabular}{|l|c|c|c|c|c|}
				\hline
				\textbf{Dispositivo}  & \textbf{F1-Score} & \textbf{Accuracy} & \textbf{Sorensen-Dice} & \textbf{Silhouette} & \textbf{Tiempo(s)} \\
				\hline
				
				
				\textbf{1} & 0.5928 & 0.7177 & 0.5928 & 0.2256 & 116.55\\
				\hline
				
				\textbf{2} & 0.4740 & 0.6433 & 0.4740 & 0.2032 & 72.102\\
				\hline
				
				
			\end{tabular}
		\end{adjustbox}
	\end{center}
\end{table}

\hfil

En una segunda prueba se utilizaron un total de 298 imágenes, pertenecientes a 5 distintas clases, las cuales se detallan a continuación:

\begin{itemize}
	\item Gato: 15 imágenes
	\item Computadora: 40 imágenes
	\item Bebida: 30 imágenes
	\item Memes: 68 imágenes
	\item Screenshots: 145 imágenes
\end{itemize} 


El objetivo de esta prueba fue observar como se comporta el motor ante un aumento considerado de la cantidad de imágenes a procesar, además de que se encuentren muchas más imágenes de una sola categoría con respecto a las otras. Como se puede ver en la Tabla \ref{tab:prueba2}, se obtuvieron buenas métricas. Se puede observar que la \textit{Silhouette} en general fue baja, ya que el algoritmo creó muchos grupos de 2 o 3 imágenes, haciendo que esta métrica esté muy cercana al valor 0 (solapamiento entre grupos). Vale aclarar que dentro de estos clusters chicos, las imágenes tenían mucha relación entre sí, por lo que subjetivamente se podría considerar como una buena agrupación. 

Otro punto a destacar, es cómo al aumentar la cantidad de imágenes a procesar, el tiempo en el celular de gama mayor se reduce casi en un 50\% respecto al celular de gama media.


\begin{table}[h!]
	\begin{center}
		\caption{Resultados de la prueba 2.}
		\label{tab:prueba2}
		\begin{adjustbox}{max width=\textwidth}
			\begin{tabular}{|l|c|c|c|c|c|}
				\hline
				\textbf{Dispositivo}  & \textbf{F1-Score} & \textbf{Accuracy} & \textbf{Sorensen-Dice} & \textbf{Silhouette} & \textbf{Tiempo(s)} \\
				\hline
				
				
				\textbf{1} & 0.8453 & 0.8489 & 0.8452 & 0.0101 & 215.24\\
				\hline
				
				\textbf{2} & 0.8444 & 0.8457 & 0.8443 & -0.0162 & 138.20\\
				\hline
				
				
			\end{tabular}
		\end{adjustbox}
	\end{center}
\end{table}

\hfil

Por último, se muestra una prueba donde el objetivo fue elevar aún más el número de imágenes y clases, y así poder medir la escalabilidad del motor y su comportamiento en diferentes dispositivos. Las clases utilizadas fueron 11 con un total de 500 imágenes divididas de la siguiente manera:

\begin{itemize}
	\item Avión: 25 imágenes
	\item Bicicleta: 50 imágenes
	\item Pájaro: 35 imágenes
	\item Bus: 30 imágenes
	\item Automóvil: 70 imágenes
	\item Gato: 15 imágenes
	\item Computadora: 51 imágenes
	\item Perro: 101 imágenes
	\item Bebida: 30 imágenes
	\item Memes: 90 imágenes
	\item Fiestas: 33 imágenes
\end{itemize}

Como se puede observar en la Tabla \ref{tab:prueba3}, las métricas obtenidas en cuanto a clasificación y clustering son buenas. El inconveniente se encuentra en el tiempo de proceso, ya que fue bastante largo ($\approx$ 9 minutos para el dispositivo 1). Es por ello que fue necesario establecer un límite en relación a la cantidad de imágenes procesadas - tiempo, ya que para dispositivos gama baja/media es demasiado el tiempo que consume.

\begin{table}[h!]
	\begin{center}
		\caption{Resultados de la prueba 3.}
		\label{tab:prueba3}
		\begin{adjustbox}{max width=\textwidth}
			\begin{tabular}{|l|c|c|c|c|c|}
				\hline
				\textbf{Dispositivo}  & \textbf{F1-Score} & \textbf{Accuracy} & \textbf{Sorensen-Dice} & \textbf{Silhouette} & \textbf{Tiempo(s)} \\
				\hline
				
				
				\textbf{1} & 0.8123 & 0.804 & 0.8123 & 0.1581 & 515,38\\
				\hline
				
				\textbf{2} & 0.8142 & 0.808 & 0.8143 & 0.1321 & 335.91\\
				\hline
				
				
			\end{tabular}
		\end{adjustbox}
	\end{center}
\end{table}

\hfil

\section{Validación de la aplicación}

Con el objetivo de corroborar el correcto funcionamiento de todos los módulos que componen el sistema, verificando que actúan y responden según lo esperado, se definieron pruebas unitarias (mejor conocido en inglés como \textit{unit testing}), y un protocolo de validación donde se presentaron un conjunto de casos de prueba relacionadas a la experiencia de usuario. Todo será detallado a continuación.

\subsection{Pruebas unitarias}

De forma que las características de la aplicación sean validadas en términos
de funcionalidad, se procede a utilizar diferentes herramientas que permitan testear los módulos implementados. Esto es realizado con el fin de seguir buenas prácticas de ingeniería en software \cite{sommerville2007software}, que permitan desarrollar un producto que asegure cierta calidad en su integración y despliegue.

Las pruebas unitarias son una forma de comprobar el correcto funcionamiento de un módulo de forma aislada al resto de los componentes. Para ello se define un escenario para ejecutar las acciones de ese módulo en forma separada, y se corrobora obtener un cierto comportamiento esperado en la salida de cada una de ellas \cite{learninspy2016tesis}. Mediante la utilización de los frameworks \textbf{JUnit} y \textbf{Mockito}, se llevaron adelante las pruebas de la aplicación de forma automatizada. Gracias a ellos se fue probando de a pequeñas porciones de código. Para esto se estableció un escenario posible con datos de entrada, ejecutando las acciones de cada módulo y corroborando el comportamiento esperado en las salida de cada uno de los casos.

\subsection{Protocolo de validación}

Con el objetivo de validar que todos los módulos que componen la aplicación responden y actúan según lo esperado, se definieron un conjunto de pruebas a realizar sobre la aplicación finalizada y aquí se muestran los resultados:

\begin{itemize}
	\item \textbf{\underline{Prueba Nº 1}}
	\begin{itemize}
		\item \underline{Sujeto:} Ejecutor del proyecto
		\item \underline{Tarea:} Seleccionar ícono de ingreso al sistema dentro del menú Android.
		\item \underline{Criterio de aprobación:} Ingreso a la aplicación de forma directa sin ningún tipo de publicidad o presentación.
		\item \underline{Estado:} APROBADO
		\item \underline{Comentarios:} Una vez que se aprieta el ícono representativo, se ingresa a la aplicación sin demoras ni errores.
	\end{itemize}
	\item \textbf{\underline{Prueba Nº 2}}
	\begin{itemize}
		\item \underline{Sujeto:} Ejecutor del proyecto
		\item \underline{Tarea:} Acceder al menú de elección de directorios a procesar.
		\item \underline{Criterio de aprobación:} Acceso al explorador de archivos, pudiendo visualizar el contenido dentro de cada carpeta.
		\item \underline{Estado:} APROBADO
		\item \underline{Comentarios:} Se brinda la opción de seleccionar el directorio a procesar. Se visualizan directorios (en caso de que existan) dentro de la carpeta seleccionada, pero no su respectivo contenido (e.g imágenes, documentos, etc.)
	\end{itemize}
	\item \textbf{\underline{Prueba Nº 3}}
	\begin{itemize}
		\item \underline{Sujeto:} Ejecutor del proyecto
		\item \underline{Tarea:} Verificar estado de procesamiento de las imágenes durante la ejecución.
		\item \underline{Criterio de aprobación:} El sistema muestra en todo momento el grado de avance del procesamiento, calculado en base a la cantidad de imágenes procesadas y la cantidad total de imágenes a procesar.
		\item \underline{Estado:} APROBADO
		\item \underline{Comentarios:} Durante el procesamiento de las imágenes se puede visualizar el porcentaje de procesamiento realizado en cada momento.
	\end{itemize}
	\item \textbf{\underline{Prueba Nº 4}}
	\begin{itemize}
		\item \underline{Sujeto:} Ejecutor del proyecto
		\item \underline{Tarea:} Verificar informe de finalización de procesamiento de imágenes por parte del sistema.
		\item \underline{Criterio de aprobación:} Deberá indicar el estado de finalización (éxito o error). En caso de que haya finalizado exitosamente, a continuación deberá presentar el menú de administración del resultado.
		\item \underline{Estado:} APROBADO
		\item \underline{Comentarios:} Una vez finalizado el procesamiento, el sistema muestra la sugerencia de organización de las imágenes si finaliza de manera exitosa. En caso de finalizar con algún tipo de error, vuelve todo hacia atrás y solicita que el proceso vuelva a ejecutarse.
	\end{itemize}
	\item \textbf{\underline{Prueba Nº 5}}
	\begin{itemize}
		\item \underline{Sujeto:} Ejecutor del proyecto
		\item \underline{Tarea:} Probar las diferentes opciones de administración de imágenes y directorios sugeridos por el resultado.
		\item \underline{Criterio de aprobación:} La utilización de dichas opciones debe responder de manera fluida y realizar las tareas especificadas. Debe informar el éxito de cada tarea realizada de manera dinámica y rápida.
		\item \underline{Estado:} APROBADO
		\item \underline{Comentarios:} Se corroboró que la aplicación responda adecuadamente con las distintas opciones de administración de directorios disponibles (e.g. renombrar, mover, eliminar, etc)
	\end{itemize}
	\item \textbf{\underline{Prueba Nº 6}}
	\begin{itemize}
		\item \underline{Sujeto:} Ejecutor del proyecto
		\item \underline{Tarea:} Seleccionar el botón de confirmar el resultado final.
		\item \underline{Criterio de aprobación:} El sistema deberá brindar al usuario la opción de mover de manera permanente o copiar el resultado final.
		\item \underline{Estado:} APROBADO
		\item \underline{Comentarios:} La aplicación responde correctamente al presionar el botón confirmar, mostrando las diferentes opciones, ya sea copiar o mover el resultado final, o bien cancelar y volver a la pantalla anterior.
	\end{itemize}
	\item \textbf{\underline{Prueba Nº 7}}
	\begin{itemize}
		\item \underline{Sujeto:} Ejecutor del proyecto
		\item \underline{Tarea:} Mover de manera permanente el resultado final hacia una nueva carpeta.
		\item \underline{Criterio de aprobación:} La aplicación deberá mover las imágenes desde su ubicación original hacia la nueva carpeta generada.
		\item \underline{Estado:} APROBADO
		\item \underline{Comentarios:} Los resultados se encuentran en la ubicación esperada luego de confirmarlos, y son eliminados de su ubicación anterior.
	\end{itemize}
	\item \textbf{\underline{Prueba Nº 8}}
	\begin{itemize}
		\item \underline{Sujeto:} Ejecutor del proyecto
		\item \underline{Tarea:} Copiar el resultado final hacia una nueva carpeta.
		\item \underline{Criterio de aprobación:} La aplicación deberá copiar (sin eliminar las imágenes desde su ubicación original) hacia la nueva carpeta generada.
		\item \underline{Estado:} APROBADO
		\item \underline{Comentarios:} La aplicación copia los archivos de manera correcta a la ubicación indicada una vez que los resultados son confirmados.
	\end{itemize}
	\item \textbf{\underline{Prueba Nº 9}}
	\begin{itemize}
		\item \underline{Sujeto:} Ejecutor del proyecto
		\item \underline{Tarea:} Seleccionar el botón de descartar el resultado final.
		\item \underline{Criterio de aprobación:} La ubicación de cada imagen deberá permanecer inalterada y en el estado original previo a la utilización de la aplicación. Informar al usuario el éxito de la operación.
		\item \underline{Estado:} APROBADO
		\item \underline{Comentarios:} El estado original de las imágenes procesadas se conserva correctamente luego de descartar un resultado de agrupamiento.
	\end{itemize}
\end{itemize}